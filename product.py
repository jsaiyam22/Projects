# -*- coding: utf-8 -*-
"""product.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Wwluwn77PQ9Rfed5rn9A-GR0uSpombvd
"""

import pandas as pd 
import re  
import nltk
nltk.download('stopwords')
nltk.download('punkt')
nltk.download('wordnet')
nltk.download('omw-1.4')

from google.colab import drive
drive.mount('/content/drive')

data = pd.read_csv(r"/content/drive/MyDrive/sanyam_6_miniproject/Updated.csv")
data.head()

dataframe = data[['asin','overall','reviewText']]
dataframe.head(20)

display = dataframe['overall'].value_counts()
print(display)

positive_reviews = dataframe.loc[dataframe['overall'] > 3]
positive_reviews.insert(3,'Reaction','Positive')
negative_reviews = dataframe.loc[dataframe['overall'] < 3]
negative_reviews.insert(3,'Reaction','Negative')

reactions = pd.concat([positive_reviews, negative_reviews], ignore_index=True)

reactions.head(10)

#checking missing values
reactions.isnull().sum()

#removal of missing values from Reviews column
reactions.dropna(subset=['reviewText'], inplace=True)
reactions.isnull().sum()

#using lambda function which is a anonymous function which takes any number of arguments and execute a an expression
df = reactions.groupby('Reaction').apply(lambda x: x.sample(n=15000)).reset_index(drop = True)
df['Reaction'].value_counts()

df.info

def clean(text):
    text = text.lower() #Converting all reviews to lower case
    modified_string = re.sub('[^A-Za-z0â€“9]+' , ' ', text)
    return(modified_string)
df['reviewText'] = df['reviewText'].apply(clean)
df.head(10)
# Removing the stopwords
from nltk.corpus import stopwords
stop_words = stopwords.words('english')
df['reviewText'] = df['reviewText'].apply(lambda x: " ".join([w for w in x.split() if len(w)>3]))
df.head(20)

from nltk import word_tokenize
for x in df['reviewText']:
     x=word_tokenize(x)
print(x)

from nltk .stem import WordNetLemmatizer
wordnet = WordNetLemmatizer()
tokens=[wordnet.lemmatize(word) for word in x]
print(tokens)
df['reviewText']=[" ".join([wordnet.lemmatize(j) for j in i.split()]) for i in df['reviewText']]
df.head(20)

from sklearn.feature_extraction.text import TfidfVectorizer
tfidfvectorizer = TfidfVectorizer(analyzer='word',stop_words= 'english')
result = tfidfvectorizer.fit_transform(df['reviewText'])
print(result)

from sklearn.model_selection import train_test_split
xtrain, x_test, ytrain, y_test = train_test_split(result, df['Reaction'], random_state=1,test_size=0.30)

# checking shape of dataset
print("shape of xtrain is :",xtrain.shape)
print("shape of ytrain is :",ytrain.shape)
print("shape of x_test is :",x_test.shape)
print("shape of y_test is :",y_test.shape)

from sklearn.naive_bayes import MultinomialNB
from sklearn.metrics import confusion_matrix
NB = MultinomialNB().fit(xtrain, ytrain)
pred = NB.predict(x_test)
print('Accuracy of NB  classifier on training set: {:.2f}' ,format(NB.score(xtrain, ytrain)))
print('Accuracy of NB classifier on test set: {:.2f}' ,format(NB.score(x_test, y_test)))
cm = confusion_matrix(y_test, pred)
cm

from sklearn.linear_model import LogisticRegression
from sklearn.metrics import confusion_matrix
logreg = LogisticRegression().fit(xtrain, ytrain)
pred = logreg.predict(x_test)
print('Accuracy of Logistic classifier on training set {:.2f}' ,format(logreg.score(xtrain, ytrain)))
print('Accuracy of Logistic classifier on test set {:.2f}' ,format(logreg.score(x_test, y_test)))
cm = confusion_matrix(y_test, pred)
cm
model = LogisticRegression()
filename = 'finalized_LR_model.sav'

from sklearn.svm import LinearSVC
from sklearn.metrics import confusion_matrix
svc = LinearSVC().fit(xtrain, ytrain)
pred = svc.predict(x_test)
print('Accuracy of LinearSVC on training set {:.2f}' ,format(svc.score(xtrain, ytrain)))
print('Accuracy of Linear SVC on test set {:.2f}' ,format(svc.score(x_test, y_test)))
cm = confusion_matrix(y_test, pred)
cm

text = "cream is very bad"
svc.predict(tfidfvectorizer.transform([text]))[0]

